{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dbc3e83b-4991-4adb-8e65-607598cfa8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score,precision_recall_fscore_support\n",
    "from sklearn.metrics import f1_score,roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier,ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "df = pd.read_csv(r\"UNSW-NB15.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "44df7ae4-c7f2-4625-9353-286c5ff3d483",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = df['attack_cat'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "98335927-8ffc-4863-aeb3-26808db3b712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dur', 'proto', 'service', 'state', 'spkts', 'dpkts', 'sbytes', 'dbytes', 'sttl', 'dttl', 'sload', 'dload', 'sloss', 'dloss', 'sintpkt', 'dintpkt', 'sjit', 'djit', 'swin', 'stcpb', 'dtcpb', 'dwin', 'tcprtt', 'synack', 'ackdat', 'smeansz', 'dmeansz', 'trans_depth', 'res_bdy_len', 'ct_srv_src', 'ct_state_ttl', 'ct_dst_ltm', 'ct_src_dport_ltm', 'ct_dst_sport_ltm', 'ct_dst_src_ltm', 'is_ftp_login', 'ct_ftp_cmd', 'ct_flw_http_mthd', 'ct_src_ltm', 'ct_srv_dst', 'is_sm_ips_ports', 'attack_cat']\n"
     ]
    }
   ],
   "source": [
    "features = ['dur', 'proto', 'service', 'state', 'spkts', 'dpkts', 'sbytes', 'dbytes', 'sttl', 'dttl', 'sload', 'dload', 'sloss', 'dloss',\n",
    " 'sintpkt', 'dintpkt', 'sjit', 'djit', 'swin', 'stcpb', 'dtcpb', 'dwin', 'tcprtt', 'synack', 'ackdat', 'smeansz', 'dmeansz', 'trans_depth',\n",
    " 'res_bdy_len', 'ct_srv_src', 'ct_state_ttl', 'ct_dst_ltm', 'ct_src_dport_ltm', 'ct_dst_sport_ltm', 'ct_dst_src_ltm', 'is_ftp_login',\n",
    " 'ct_ftp_cmd', 'ct_flw_http_mthd', 'ct_src_ltm', 'ct_srv_dst', 'is_sm_ips_ports', 'attack_cat']\n",
    "\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "737237d4-da85-4e72-9bac-4ebde9ca76c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d2464fc3-1fc1-49d6-8b43-d82c3cfbbf16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dur</th>\n",
       "      <th>proto</th>\n",
       "      <th>service</th>\n",
       "      <th>state</th>\n",
       "      <th>spkts</th>\n",
       "      <th>dpkts</th>\n",
       "      <th>sbytes</th>\n",
       "      <th>dbytes</th>\n",
       "      <th>sttl</th>\n",
       "      <th>dttl</th>\n",
       "      <th>...</th>\n",
       "      <th>ct_src_dport_ltm</th>\n",
       "      <th>ct_dst_sport_ltm</th>\n",
       "      <th>ct_dst_src_ltm</th>\n",
       "      <th>is_ftp_login</th>\n",
       "      <th>ct_ftp_cmd</th>\n",
       "      <th>ct_flw_http_mthd</th>\n",
       "      <th>ct_src_ltm</th>\n",
       "      <th>ct_srv_dst</th>\n",
       "      <th>is_sm_ips_ports</th>\n",
       "      <th>attack_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001055</td>\n",
       "      <td>udp</td>\n",
       "      <td>dns</td>\n",
       "      <td>CON</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>132</td>\n",
       "      <td>164</td>\n",
       "      <td>31</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.036133</td>\n",
       "      <td>udp</td>\n",
       "      <td>-</td>\n",
       "      <td>CON</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>528</td>\n",
       "      <td>304</td>\n",
       "      <td>31</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001119</td>\n",
       "      <td>udp</td>\n",
       "      <td>dns</td>\n",
       "      <td>CON</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>146</td>\n",
       "      <td>178</td>\n",
       "      <td>31</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001209</td>\n",
       "      <td>udp</td>\n",
       "      <td>dns</td>\n",
       "      <td>CON</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>132</td>\n",
       "      <td>164</td>\n",
       "      <td>31</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001169</td>\n",
       "      <td>udp</td>\n",
       "      <td>dns</td>\n",
       "      <td>CON</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>146</td>\n",
       "      <td>178</td>\n",
       "      <td>31</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2539734</th>\n",
       "      <td>0.087306</td>\n",
       "      <td>tcp</td>\n",
       "      <td>ftp-data</td>\n",
       "      <td>FIN</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>320</td>\n",
       "      <td>1828</td>\n",
       "      <td>31</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2539735</th>\n",
       "      <td>0.365058</td>\n",
       "      <td>tcp</td>\n",
       "      <td>ftp</td>\n",
       "      <td>CON</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>456</td>\n",
       "      <td>346</td>\n",
       "      <td>31</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2539736</th>\n",
       "      <td>6.335154</td>\n",
       "      <td>tcp</td>\n",
       "      <td>ftp</td>\n",
       "      <td>CON</td>\n",
       "      <td>32</td>\n",
       "      <td>30</td>\n",
       "      <td>1802</td>\n",
       "      <td>2088</td>\n",
       "      <td>31</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2539737</th>\n",
       "      <td>2.200934</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>CON</td>\n",
       "      <td>58</td>\n",
       "      <td>116</td>\n",
       "      <td>3498</td>\n",
       "      <td>166054</td>\n",
       "      <td>31</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2539738</th>\n",
       "      <td>0.942984</td>\n",
       "      <td>tcp</td>\n",
       "      <td>pop3</td>\n",
       "      <td>CON</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>574</td>\n",
       "      <td>676</td>\n",
       "      <td>62</td>\n",
       "      <td>252</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Exploits</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2539739 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              dur proto   service state  spkts  dpkts  sbytes  dbytes  sttl  \\\n",
       "0        0.001055   udp       dns   CON      2      2     132     164    31   \n",
       "1        0.036133   udp         -   CON      4      4     528     304    31   \n",
       "2        0.001119   udp       dns   CON      2      2     146     178    31   \n",
       "3        0.001209   udp       dns   CON      2      2     132     164    31   \n",
       "4        0.001169   udp       dns   CON      2      2     146     178    31   \n",
       "...           ...   ...       ...   ...    ...    ...     ...     ...   ...   \n",
       "2539734  0.087306   tcp  ftp-data   FIN      6      8     320    1828    31   \n",
       "2539735  0.365058   tcp       ftp   CON      8      6     456     346    31   \n",
       "2539736  6.335154   tcp       ftp   CON     32     30    1802    2088    31   \n",
       "2539737  2.200934   tcp      http   CON     58    116    3498  166054    31   \n",
       "2539738  0.942984   tcp      pop3   CON     12     12     574     676    62   \n",
       "\n",
       "         dttl  ...  ct_src_dport_ltm  ct_dst_sport_ltm  ct_dst_src_ltm  \\\n",
       "0          29  ...                 1                 1               1   \n",
       "1          29  ...                 1                 1               2   \n",
       "2          29  ...                 2                 1               1   \n",
       "3          29  ...                 1                 1               1   \n",
       "4          29  ...                 1                 1               1   \n",
       "...       ...  ...               ...               ...             ...   \n",
       "2539734    29  ...                 1                 1               3   \n",
       "2539735    29  ...                 2                 2               2   \n",
       "2539736    29  ...                 2                 2               2   \n",
       "2539737    29  ...                 2                 2               2   \n",
       "2539738   252  ...                 2                 2               2   \n",
       "\n",
       "         is_ftp_login  ct_ftp_cmd  ct_flw_http_mthd  ct_src_ltm  ct_srv_dst  \\\n",
       "0                 0.0         0.0               0.0           3           7   \n",
       "1                 0.0         0.0               0.0           3           4   \n",
       "2                 0.0         0.0               0.0           2           8   \n",
       "3                 0.0         0.0               0.0           1           9   \n",
       "4                 0.0         0.0               0.0           1           9   \n",
       "...               ...         ...               ...         ...         ...   \n",
       "2539734          -1.0        -1.0              -1.0           3           2   \n",
       "2539735           2.0         2.0              -1.0           2           2   \n",
       "2539736           2.0         2.0              -1.0           2           2   \n",
       "2539737          -1.0        -1.0               2.0           4           1   \n",
       "2539738          -1.0        -1.0              -1.0           4           1   \n",
       "\n",
       "         is_sm_ips_ports  attack_cat  \n",
       "0                      0      Normal  \n",
       "1                      0      Normal  \n",
       "2                      0      Normal  \n",
       "3                      0      Normal  \n",
       "4                      0      Normal  \n",
       "...                  ...         ...  \n",
       "2539734                0      Normal  \n",
       "2539735                0      Normal  \n",
       "2539736                0      Normal  \n",
       "2539737                0      Normal  \n",
       "2539738                0    Exploits  \n",
       "\n",
       "[2539739 rows x 42 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b3486a8c-8313-4255-84a2-49aa20ee45aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelencoder = LabelEncoder()\n",
    "for col_name in df.dtypes[df.dtypes == 'object'].index:\n",
    "      df[col_name] = labelencoder.fit_transform(df[col_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "11dce374-48ea-435d-aa17-ea379165e3c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dur</th>\n",
       "      <th>proto</th>\n",
       "      <th>service</th>\n",
       "      <th>state</th>\n",
       "      <th>spkts</th>\n",
       "      <th>dpkts</th>\n",
       "      <th>sbytes</th>\n",
       "      <th>dbytes</th>\n",
       "      <th>sttl</th>\n",
       "      <th>dttl</th>\n",
       "      <th>...</th>\n",
       "      <th>ct_src_dport_ltm</th>\n",
       "      <th>ct_dst_sport_ltm</th>\n",
       "      <th>ct_dst_src_ltm</th>\n",
       "      <th>is_ftp_login</th>\n",
       "      <th>ct_ftp_cmd</th>\n",
       "      <th>ct_flw_http_mthd</th>\n",
       "      <th>ct_src_ltm</th>\n",
       "      <th>ct_srv_dst</th>\n",
       "      <th>is_sm_ips_ports</th>\n",
       "      <th>attack_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001055</td>\n",
       "      <td>119</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>132</td>\n",
       "      <td>164</td>\n",
       "      <td>31</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.036133</td>\n",
       "      <td>119</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>528</td>\n",
       "      <td>304</td>\n",
       "      <td>31</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001119</td>\n",
       "      <td>119</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>146</td>\n",
       "      <td>178</td>\n",
       "      <td>31</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001209</td>\n",
       "      <td>119</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>132</td>\n",
       "      <td>164</td>\n",
       "      <td>31</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001169</td>\n",
       "      <td>119</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>146</td>\n",
       "      <td>178</td>\n",
       "      <td>31</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2539734</th>\n",
       "      <td>0.087306</td>\n",
       "      <td>113</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>320</td>\n",
       "      <td>1828</td>\n",
       "      <td>31</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2539735</th>\n",
       "      <td>0.365058</td>\n",
       "      <td>113</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>456</td>\n",
       "      <td>346</td>\n",
       "      <td>31</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2539736</th>\n",
       "      <td>6.335154</td>\n",
       "      <td>113</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>30</td>\n",
       "      <td>1802</td>\n",
       "      <td>2088</td>\n",
       "      <td>31</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2539737</th>\n",
       "      <td>2.200934</td>\n",
       "      <td>113</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>58</td>\n",
       "      <td>116</td>\n",
       "      <td>3498</td>\n",
       "      <td>166054</td>\n",
       "      <td>31</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2539738</th>\n",
       "      <td>0.942984</td>\n",
       "      <td>113</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>574</td>\n",
       "      <td>676</td>\n",
       "      <td>62</td>\n",
       "      <td>252</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2539739 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              dur  proto  service  state  spkts  dpkts  sbytes  dbytes  sttl  \\\n",
       "0        0.001055    119        2      2      2      2     132     164    31   \n",
       "1        0.036133    119        0      2      4      4     528     304    31   \n",
       "2        0.001119    119        2      2      2      2     146     178    31   \n",
       "3        0.001209    119        2      2      2      2     132     164    31   \n",
       "4        0.001169    119        2      2      2      2     146     178    31   \n",
       "...           ...    ...      ...    ...    ...    ...     ...     ...   ...   \n",
       "2539734  0.087306    113        4      5      6      8     320    1828    31   \n",
       "2539735  0.365058    113        3      2      8      6     456     346    31   \n",
       "2539736  6.335154    113        3      2     32     30    1802    2088    31   \n",
       "2539737  2.200934    113        5      2     58    116    3498  166054    31   \n",
       "2539738  0.942984    113        7      2     12     12     574     676    62   \n",
       "\n",
       "         dttl  ...  ct_src_dport_ltm  ct_dst_sport_ltm  ct_dst_src_ltm  \\\n",
       "0          29  ...                 1                 1               1   \n",
       "1          29  ...                 1                 1               2   \n",
       "2          29  ...                 2                 1               1   \n",
       "3          29  ...                 1                 1               1   \n",
       "4          29  ...                 1                 1               1   \n",
       "...       ...  ...               ...               ...             ...   \n",
       "2539734    29  ...                 1                 1               3   \n",
       "2539735    29  ...                 2                 2               2   \n",
       "2539736    29  ...                 2                 2               2   \n",
       "2539737    29  ...                 2                 2               2   \n",
       "2539738   252  ...                 2                 2               2   \n",
       "\n",
       "         is_ftp_login  ct_ftp_cmd  ct_flw_http_mthd  ct_src_ltm  ct_srv_dst  \\\n",
       "0                 0.0         0.0               0.0           3           7   \n",
       "1                 0.0         0.0               0.0           3           4   \n",
       "2                 0.0         0.0               0.0           2           8   \n",
       "3                 0.0         0.0               0.0           1           9   \n",
       "4                 0.0         0.0               0.0           1           9   \n",
       "...               ...         ...               ...         ...         ...   \n",
       "2539734          -1.0        -1.0              -1.0           3           2   \n",
       "2539735           2.0         2.0              -1.0           2           2   \n",
       "2539736           2.0         2.0              -1.0           2           2   \n",
       "2539737          -1.0        -1.0               2.0           4           1   \n",
       "2539738          -1.0        -1.0              -1.0           4           1   \n",
       "\n",
       "         is_sm_ips_ports  attack_cat  \n",
       "0                      0           6  \n",
       "1                      0           6  \n",
       "2                      0           6  \n",
       "3                      0           6  \n",
       "4                      0           6  \n",
       "...                  ...         ...  \n",
       "2539734                0           6  \n",
       "2539735                0           6  \n",
       "2539736                0           6  \n",
       "2539737                0           6  \n",
       "2539738                0           3  \n",
       "\n",
       "[2539739 rows x 42 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fb08452f-fae5-4020-8008-14c26cee2200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from imblearn.over_sampling import SMOTE\n",
    "# from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# # Load the dataset\n",
    "# # df = pd.read_csv('UNSW-NB15.csv')\n",
    "\n",
    "# # Inspect the dataset\n",
    "# print(df.head())\n",
    "# print(df['attack_cat'].value_counts())  # Replace 'target' with your actual target column name\n",
    "\n",
    "# # Separate features and target\n",
    "# X = df.drop('attack_cat', axis=1)  # Replace 'target' with your actual target column name\n",
    "# y = df['attack_cat']\n",
    "\n",
    "# # Apply SMOTE for oversampling\n",
    "# smote = SMOTE(random_state=42)\n",
    "# X_res, y_res = smote.fit_resample(X, y)\n",
    "# df_res = pd.DataFrame(X_res, columns=X.columns)\n",
    "# df_res['attack_cat'] = y_res\n",
    "# df_res.to_csv('oversampled_dataset.csv', index=False)\n",
    "# print(\"After SMOTE oversampling:\")\n",
    "# print(df_res['attack_cat'].value_counts())\n",
    "\n",
    "# # Apply RandomUnderSampler for undersampling\n",
    "# undersample = RandomUnderSampler(random_state=42)\n",
    "# X_res, y_res = undersample.fit_resample(X, y)\n",
    "# df_res = pd.DataFrame(X_res, columns=X.columns)\n",
    "# df_res['attack_cat'] = y_res\n",
    "# df_res.to_csv('undersampled_dataset.csv', index=False)\n",
    "# print(\"After Random undersampling:\")\n",
    "# print(df_res['attack_cat'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0e3fe4a8-09f5-484f-8d31-06d6e3a9a77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('attack_cat', axis=1)  # Replace 'target' with your actual target column name\n",
    "y = df['attack_cat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0783d7cf-f6f7-45f4-9c3a-7a9eeb8e5dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "class_counts = Counter(y)\n",
    "sampling_strategy = {class_label: int(0.10 * max(class_counts.values())) for class_label in class_counts}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5fb1eab8-7c92-4a99-af88-054b112581dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({6: 2218456,\n",
       "         5: 215481,\n",
       "         3: 44525,\n",
       "         4: 24246,\n",
       "         2: 16353,\n",
       "         7: 13987,\n",
       "         0: 2677,\n",
       "         1: 2329,\n",
       "         8: 1511,\n",
       "         9: 174})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ad422578-1f77-42e5-abfc-2fb09a551484",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{6: 221845,\n",
       " 3: 221845,\n",
       " 7: 221845,\n",
       " 2: 221845,\n",
       " 5: 221845,\n",
       " 8: 221845,\n",
       " 4: 221845,\n",
       " 9: 221845,\n",
       " 1: 221845,\n",
       " 0: 221845}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampling_strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "809418fd-a247-46b3-9049-937eba848d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_strategy[6] = 2218456"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f3f269fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dur</th>\n",
       "      <th>proto</th>\n",
       "      <th>service</th>\n",
       "      <th>state</th>\n",
       "      <th>spkts</th>\n",
       "      <th>dpkts</th>\n",
       "      <th>sbytes</th>\n",
       "      <th>dbytes</th>\n",
       "      <th>sttl</th>\n",
       "      <th>dttl</th>\n",
       "      <th>...</th>\n",
       "      <th>ct_src_dport_ltm</th>\n",
       "      <th>ct_dst_sport_ltm</th>\n",
       "      <th>ct_dst_src_ltm</th>\n",
       "      <th>is_ftp_login</th>\n",
       "      <th>ct_ftp_cmd</th>\n",
       "      <th>ct_flw_http_mthd</th>\n",
       "      <th>ct_src_ltm</th>\n",
       "      <th>ct_srv_dst</th>\n",
       "      <th>is_sm_ips_ports</th>\n",
       "      <th>attack_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001055</td>\n",
       "      <td>119</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>132</td>\n",
       "      <td>164</td>\n",
       "      <td>31</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.036133</td>\n",
       "      <td>119</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>528</td>\n",
       "      <td>304</td>\n",
       "      <td>31</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001119</td>\n",
       "      <td>119</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>146</td>\n",
       "      <td>178</td>\n",
       "      <td>31</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001209</td>\n",
       "      <td>119</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>132</td>\n",
       "      <td>164</td>\n",
       "      <td>31</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001169</td>\n",
       "      <td>119</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>146</td>\n",
       "      <td>178</td>\n",
       "      <td>31</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2539734</th>\n",
       "      <td>0.087306</td>\n",
       "      <td>113</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>320</td>\n",
       "      <td>1828</td>\n",
       "      <td>31</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2539735</th>\n",
       "      <td>0.365058</td>\n",
       "      <td>113</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>456</td>\n",
       "      <td>346</td>\n",
       "      <td>31</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2539736</th>\n",
       "      <td>6.335154</td>\n",
       "      <td>113</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>30</td>\n",
       "      <td>1802</td>\n",
       "      <td>2088</td>\n",
       "      <td>31</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2539737</th>\n",
       "      <td>2.200934</td>\n",
       "      <td>113</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>58</td>\n",
       "      <td>116</td>\n",
       "      <td>3498</td>\n",
       "      <td>166054</td>\n",
       "      <td>31</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2539738</th>\n",
       "      <td>0.942984</td>\n",
       "      <td>113</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>574</td>\n",
       "      <td>676</td>\n",
       "      <td>62</td>\n",
       "      <td>252</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2539739 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              dur  proto  service  state  spkts  dpkts  sbytes  dbytes  sttl  \\\n",
       "0        0.001055    119        2      2      2      2     132     164    31   \n",
       "1        0.036133    119        0      2      4      4     528     304    31   \n",
       "2        0.001119    119        2      2      2      2     146     178    31   \n",
       "3        0.001209    119        2      2      2      2     132     164    31   \n",
       "4        0.001169    119        2      2      2      2     146     178    31   \n",
       "...           ...    ...      ...    ...    ...    ...     ...     ...   ...   \n",
       "2539734  0.087306    113        4      5      6      8     320    1828    31   \n",
       "2539735  0.365058    113        3      2      8      6     456     346    31   \n",
       "2539736  6.335154    113        3      2     32     30    1802    2088    31   \n",
       "2539737  2.200934    113        5      2     58    116    3498  166054    31   \n",
       "2539738  0.942984    113        7      2     12     12     574     676    62   \n",
       "\n",
       "         dttl  ...  ct_src_dport_ltm  ct_dst_sport_ltm  ct_dst_src_ltm  \\\n",
       "0          29  ...                 1                 1               1   \n",
       "1          29  ...                 1                 1               2   \n",
       "2          29  ...                 2                 1               1   \n",
       "3          29  ...                 1                 1               1   \n",
       "4          29  ...                 1                 1               1   \n",
       "...       ...  ...               ...               ...             ...   \n",
       "2539734    29  ...                 1                 1               3   \n",
       "2539735    29  ...                 2                 2               2   \n",
       "2539736    29  ...                 2                 2               2   \n",
       "2539737    29  ...                 2                 2               2   \n",
       "2539738   252  ...                 2                 2               2   \n",
       "\n",
       "         is_ftp_login  ct_ftp_cmd  ct_flw_http_mthd  ct_src_ltm  ct_srv_dst  \\\n",
       "0                 0.0         0.0               0.0           3           7   \n",
       "1                 0.0         0.0               0.0           3           4   \n",
       "2                 0.0         0.0               0.0           2           8   \n",
       "3                 0.0         0.0               0.0           1           9   \n",
       "4                 0.0         0.0               0.0           1           9   \n",
       "...               ...         ...               ...         ...         ...   \n",
       "2539734          -1.0        -1.0              -1.0           3           2   \n",
       "2539735           2.0         2.0              -1.0           2           2   \n",
       "2539736           2.0         2.0              -1.0           2           2   \n",
       "2539737          -1.0        -1.0               2.0           4           1   \n",
       "2539738          -1.0        -1.0              -1.0           4           1   \n",
       "\n",
       "         is_sm_ips_ports  attack_cat  \n",
       "0                      0           6  \n",
       "1                      0           6  \n",
       "2                      0           6  \n",
       "3                      0           6  \n",
       "4                      0           6  \n",
       "...                  ...         ...  \n",
       "2539734                0           6  \n",
       "2539735                0           6  \n",
       "2539736                0           6  \n",
       "2539737                0           6  \n",
       "2539738                0           3  \n",
       "\n",
       "[2539739 rows x 42 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b2cbdc64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  dur     spkts     dpkts    sbytes    dbytes      sttl  \\\n",
      "0        1.200687e-07  0.000188  0.000182  0.000009  0.000011  0.121569   \n",
      "1        4.112267e-06  0.000376  0.000363  0.000037  0.000021  0.121569   \n",
      "2        1.273525e-07  0.000188  0.000182  0.000010  0.000012  0.121569   \n",
      "3        1.375953e-07  0.000188  0.000182  0.000009  0.000011  0.121569   \n",
      "4        1.330429e-07  0.000188  0.000182  0.000010  0.000012  0.121569   \n",
      "...               ...       ...       ...       ...       ...       ...   \n",
      "2539734  9.936224e-06  0.000564  0.000726  0.000022  0.000125  0.121569   \n",
      "2539735  4.154695e-05  0.000751  0.000545  0.000032  0.000024  0.121569   \n",
      "2539736  7.209987e-04  0.003006  0.002723  0.000126  0.000142  0.121569   \n",
      "2539737  2.504865e-04  0.005448  0.010528  0.000244  0.011329  0.121569   \n",
      "2539738  1.073202e-04  0.001127  0.001089  0.000040  0.000046  0.243137   \n",
      "\n",
      "             dttl         sload     dload     sloss  ...  is_ftp_login  \\\n",
      "0        0.114173  8.357948e-05  0.004829  0.000000  ...           0.2   \n",
      "1        0.114173  1.464196e-05  0.000392  0.000000  ...           0.2   \n",
      "2        0.114173  8.715673e-05  0.004942  0.000000  ...           0.2   \n",
      "3        0.114173  7.293329e-05  0.004214  0.000000  ...           0.2   \n",
      "4        0.114173  8.342890e-05  0.004730  0.000000  ...           0.2   \n",
      "...           ...           ...       ...       ...  ...           ...   \n",
      "2539734  0.114173  4.085783e-06  0.001139  0.000188  ...           0.0   \n",
      "2539735  0.114173  1.460223e-06  0.000049  0.000376  ...           0.6   \n",
      "2539736  0.114173  3.682097e-07  0.000020  0.001316  ...           0.6   \n",
      "2539737  0.114173  2.086926e-06  0.004647  0.000376  ...           0.0   \n",
      "2539738  0.992126  7.466455e-07  0.000041  0.000940  ...           0.0   \n",
      "\n",
      "         ct_ftp_cmd  ct_flw_http_mthd  ct_src_ltm  ct_srv_dst  \\\n",
      "0          0.111111          0.027027    0.030303    0.090909   \n",
      "1          0.111111          0.027027    0.030303    0.045455   \n",
      "2          0.111111          0.027027    0.015152    0.106061   \n",
      "3          0.111111          0.027027    0.000000    0.121212   \n",
      "4          0.111111          0.027027    0.000000    0.121212   \n",
      "...             ...               ...         ...         ...   \n",
      "2539734    0.000000          0.000000    0.030303    0.015152   \n",
      "2539735    0.333333          0.000000    0.015152    0.015152   \n",
      "2539736    0.333333          0.000000    0.015152    0.015152   \n",
      "2539737    0.000000          0.081081    0.045455    0.000000   \n",
      "2539738    0.000000          0.000000    0.045455    0.000000   \n",
      "\n",
      "         is_sm_ips_ports  proto  service  state  attack_cat  \n",
      "0                    0.0    119        2      2           6  \n",
      "1                    0.0    119        0      2           6  \n",
      "2                    0.0    119        2      2           6  \n",
      "3                    0.0    119        2      2           6  \n",
      "4                    0.0    119        2      2           6  \n",
      "...                  ...    ...      ...    ...         ...  \n",
      "2539734              0.0    113        4      5           6  \n",
      "2539735              0.0    113        3      2           6  \n",
      "2539736              0.0    113        3      2           6  \n",
      "2539737              0.0    113        5      2           6  \n",
      "2539738              0.0    113        7      2           3  \n",
      "\n",
      "[2539739 rows x 42 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Load your dataset (replace with your data loading code)\n",
    "# df = pd.read_csv('UNSW-NB15.csv')\n",
    "\n",
    "# Suppose 'attack_cat', 'proto', 'service', 'state' are columns to exclude from features\n",
    "exclude_columns = ['proto', 'service', 'state','attack_cat']\n",
    "\n",
    "# Separate features and target\n",
    "features = df.drop(exclude_columns, axis=1)\n",
    "target_columns = ['proto', 'service', 'state','attack_cat']\n",
    "target = df[target_columns]  # Assuming these are the target columns\n",
    "\n",
    "# Normalize features (excluding target) with non-negative values\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))  # Set range to 0-1 for non-negative values\n",
    "scaled_features = scaler.fit_transform(features)\n",
    "features_scaled = pd.DataFrame(scaled_features, columns=features.columns)\n",
    "\n",
    "# Combine scaled features with the original target columns\n",
    "df = pd.concat([features_scaled, target], axis=1)\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8928dc7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dur</th>\n",
       "      <th>spkts</th>\n",
       "      <th>dpkts</th>\n",
       "      <th>sbytes</th>\n",
       "      <th>dbytes</th>\n",
       "      <th>sttl</th>\n",
       "      <th>dttl</th>\n",
       "      <th>sload</th>\n",
       "      <th>dload</th>\n",
       "      <th>sloss</th>\n",
       "      <th>...</th>\n",
       "      <th>is_ftp_login</th>\n",
       "      <th>ct_ftp_cmd</th>\n",
       "      <th>ct_flw_http_mthd</th>\n",
       "      <th>ct_src_ltm</th>\n",
       "      <th>ct_srv_dst</th>\n",
       "      <th>is_sm_ips_ports</th>\n",
       "      <th>proto</th>\n",
       "      <th>service</th>\n",
       "      <th>state</th>\n",
       "      <th>attack_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.200687e-07</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.121569</td>\n",
       "      <td>0.114173</td>\n",
       "      <td>8.357948e-05</td>\n",
       "      <td>0.004829</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>119</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.112267e-06</td>\n",
       "      <td>0.000376</td>\n",
       "      <td>0.000363</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.121569</td>\n",
       "      <td>0.114173</td>\n",
       "      <td>1.464196e-05</td>\n",
       "      <td>0.000392</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.0</td>\n",
       "      <td>119</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.273525e-07</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.121569</td>\n",
       "      <td>0.114173</td>\n",
       "      <td>8.715673e-05</td>\n",
       "      <td>0.004942</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.015152</td>\n",
       "      <td>0.106061</td>\n",
       "      <td>0.0</td>\n",
       "      <td>119</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.375953e-07</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.121569</td>\n",
       "      <td>0.114173</td>\n",
       "      <td>7.293329e-05</td>\n",
       "      <td>0.004214</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.121212</td>\n",
       "      <td>0.0</td>\n",
       "      <td>119</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.330429e-07</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.121569</td>\n",
       "      <td>0.114173</td>\n",
       "      <td>8.342890e-05</td>\n",
       "      <td>0.004730</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.121212</td>\n",
       "      <td>0.0</td>\n",
       "      <td>119</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2539734</th>\n",
       "      <td>9.936224e-06</td>\n",
       "      <td>0.000564</td>\n",
       "      <td>0.000726</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.121569</td>\n",
       "      <td>0.114173</td>\n",
       "      <td>4.085783e-06</td>\n",
       "      <td>0.001139</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.015152</td>\n",
       "      <td>0.0</td>\n",
       "      <td>113</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2539735</th>\n",
       "      <td>4.154695e-05</td>\n",
       "      <td>0.000751</td>\n",
       "      <td>0.000545</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.121569</td>\n",
       "      <td>0.114173</td>\n",
       "      <td>1.460223e-06</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000376</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015152</td>\n",
       "      <td>0.015152</td>\n",
       "      <td>0.0</td>\n",
       "      <td>113</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2539736</th>\n",
       "      <td>7.209987e-04</td>\n",
       "      <td>0.003006</td>\n",
       "      <td>0.002723</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>0.121569</td>\n",
       "      <td>0.114173</td>\n",
       "      <td>3.682097e-07</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015152</td>\n",
       "      <td>0.015152</td>\n",
       "      <td>0.0</td>\n",
       "      <td>113</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2539737</th>\n",
       "      <td>2.504865e-04</td>\n",
       "      <td>0.005448</td>\n",
       "      <td>0.010528</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>0.011329</td>\n",
       "      <td>0.121569</td>\n",
       "      <td>0.114173</td>\n",
       "      <td>2.086926e-06</td>\n",
       "      <td>0.004647</td>\n",
       "      <td>0.000376</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.081081</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>113</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2539738</th>\n",
       "      <td>1.073202e-04</td>\n",
       "      <td>0.001127</td>\n",
       "      <td>0.001089</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.243137</td>\n",
       "      <td>0.992126</td>\n",
       "      <td>7.466455e-07</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000940</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>113</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2539739 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  dur     spkts     dpkts    sbytes    dbytes      sttl  \\\n",
       "0        1.200687e-07  0.000188  0.000182  0.000009  0.000011  0.121569   \n",
       "1        4.112267e-06  0.000376  0.000363  0.000037  0.000021  0.121569   \n",
       "2        1.273525e-07  0.000188  0.000182  0.000010  0.000012  0.121569   \n",
       "3        1.375953e-07  0.000188  0.000182  0.000009  0.000011  0.121569   \n",
       "4        1.330429e-07  0.000188  0.000182  0.000010  0.000012  0.121569   \n",
       "...               ...       ...       ...       ...       ...       ...   \n",
       "2539734  9.936224e-06  0.000564  0.000726  0.000022  0.000125  0.121569   \n",
       "2539735  4.154695e-05  0.000751  0.000545  0.000032  0.000024  0.121569   \n",
       "2539736  7.209987e-04  0.003006  0.002723  0.000126  0.000142  0.121569   \n",
       "2539737  2.504865e-04  0.005448  0.010528  0.000244  0.011329  0.121569   \n",
       "2539738  1.073202e-04  0.001127  0.001089  0.000040  0.000046  0.243137   \n",
       "\n",
       "             dttl         sload     dload     sloss  ...  is_ftp_login  \\\n",
       "0        0.114173  8.357948e-05  0.004829  0.000000  ...           0.2   \n",
       "1        0.114173  1.464196e-05  0.000392  0.000000  ...           0.2   \n",
       "2        0.114173  8.715673e-05  0.004942  0.000000  ...           0.2   \n",
       "3        0.114173  7.293329e-05  0.004214  0.000000  ...           0.2   \n",
       "4        0.114173  8.342890e-05  0.004730  0.000000  ...           0.2   \n",
       "...           ...           ...       ...       ...  ...           ...   \n",
       "2539734  0.114173  4.085783e-06  0.001139  0.000188  ...           0.0   \n",
       "2539735  0.114173  1.460223e-06  0.000049  0.000376  ...           0.6   \n",
       "2539736  0.114173  3.682097e-07  0.000020  0.001316  ...           0.6   \n",
       "2539737  0.114173  2.086926e-06  0.004647  0.000376  ...           0.0   \n",
       "2539738  0.992126  7.466455e-07  0.000041  0.000940  ...           0.0   \n",
       "\n",
       "         ct_ftp_cmd  ct_flw_http_mthd  ct_src_ltm  ct_srv_dst  \\\n",
       "0          0.111111          0.027027    0.030303    0.090909   \n",
       "1          0.111111          0.027027    0.030303    0.045455   \n",
       "2          0.111111          0.027027    0.015152    0.106061   \n",
       "3          0.111111          0.027027    0.000000    0.121212   \n",
       "4          0.111111          0.027027    0.000000    0.121212   \n",
       "...             ...               ...         ...         ...   \n",
       "2539734    0.000000          0.000000    0.030303    0.015152   \n",
       "2539735    0.333333          0.000000    0.015152    0.015152   \n",
       "2539736    0.333333          0.000000    0.015152    0.015152   \n",
       "2539737    0.000000          0.081081    0.045455    0.000000   \n",
       "2539738    0.000000          0.000000    0.045455    0.000000   \n",
       "\n",
       "         is_sm_ips_ports  proto  service  state  attack_cat  \n",
       "0                    0.0    119        2      2           6  \n",
       "1                    0.0    119        0      2           6  \n",
       "2                    0.0    119        2      2           6  \n",
       "3                    0.0    119        2      2           6  \n",
       "4                    0.0    119        2      2           6  \n",
       "...                  ...    ...      ...    ...         ...  \n",
       "2539734              0.0    113        4      5           6  \n",
       "2539735              0.0    113        3      2           6  \n",
       "2539736              0.0    113        3      2           6  \n",
       "2539737              0.0    113        5      2           6  \n",
       "2539738              0.0    113        7      2           3  \n",
       "\n",
       "[2539739 rows x 42 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fe7191af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6 3 7 2 5 8 4 9 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(df['attack_cat'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "729f5122-6b37-44a3-975e-a3c49c6e7f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            dur     spkts     dpkts    sbytes    dbytes      sttl      dttl  \\\n",
      "0  1.200687e-07  0.000188  0.000182  0.000009  0.000011  0.121569  0.114173   \n",
      "1  4.112267e-06  0.000376  0.000363  0.000037  0.000021  0.121569  0.114173   \n",
      "2  1.273525e-07  0.000188  0.000182  0.000010  0.000012  0.121569  0.114173   \n",
      "3  1.375953e-07  0.000188  0.000182  0.000009  0.000011  0.121569  0.114173   \n",
      "4  1.330429e-07  0.000188  0.000182  0.000010  0.000012  0.121569  0.114173   \n",
      "\n",
      "      sload     dload  sloss  ...  is_ftp_login  ct_ftp_cmd  ct_flw_http_mthd  \\\n",
      "0  0.000084  0.004829    0.0  ...           0.2    0.111111          0.027027   \n",
      "1  0.000015  0.000392    0.0  ...           0.2    0.111111          0.027027   \n",
      "2  0.000087  0.004942    0.0  ...           0.2    0.111111          0.027027   \n",
      "3  0.000073  0.004214    0.0  ...           0.2    0.111111          0.027027   \n",
      "4  0.000083  0.004730    0.0  ...           0.2    0.111111          0.027027   \n",
      "\n",
      "   ct_src_ltm  ct_srv_dst  is_sm_ips_ports  proto  service  state  attack_cat  \n",
      "0    0.030303    0.090909              0.0    119        2      2           6  \n",
      "1    0.030303    0.045455              0.0    119        0      2           6  \n",
      "2    0.015152    0.106061              0.0    119        2      2           6  \n",
      "3    0.000000    0.121212              0.0    119        2      2           6  \n",
      "4    0.000000    0.121212              0.0    119        2      2           6  \n",
      "\n",
      "[5 rows x 42 columns]\n",
      "attack_cat\n",
      "6    2218456\n",
      "5     215481\n",
      "3      44525\n",
      "4      24246\n",
      "2      16353\n",
      "7      13987\n",
      "0       2677\n",
      "1       2329\n",
      "8       1511\n",
      "9        174\n",
      "Name: count, dtype: int64\n",
      "After SMOTE oversampling:\n",
      "attack_cat\n",
      "6    2218456\n",
      "3     221845\n",
      "7     221845\n",
      "2     221845\n",
      "5     221845\n",
      "8     221845\n",
      "4     221845\n",
      "9     221845\n",
      "1     221845\n",
      "0     221845\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Load the dataset\n",
    "# df = pd.read_csv('UNSW-NB15.csv')\n",
    "\n",
    "# Inspect the dataset\n",
    "print(df.head())\n",
    "print(df['attack_cat'].value_counts())  # Replace 'target' with your actual target column name\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop('attack_cat', axis=1)  # Replace 'target' with your actual target column name\n",
    "y = df['attack_cat']\n",
    "# Apply SMOTE for oversampling\n",
    "smote = SMOTE(sampling_strategy=sampling_strategy,random_state=42)\n",
    "X_res , y_res = smote.fit_resample(X ,y)\n",
    "df_res = pd.DataFrame(X_res, columns=X.columns)\n",
    "df_res['attack_cat'] = y_res\n",
    "df_res.to_csv('oversampled_dataset.csv', index=False)\n",
    "print(\"After SMOTE oversampling:\")\n",
    "print(df_res['attack_cat'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "147e72b8-3da1-4f70-aa3d-3d0499e1d50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score,precision_recall_fscore_support\n",
    "from sklearn.metrics import f1_score,roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier,ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "df = pd.read_csv(r\"oversampled_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b2434b7b-7a21-4397-abe8-423c816d4150",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dur</th>\n",
       "      <th>spkts</th>\n",
       "      <th>dpkts</th>\n",
       "      <th>sbytes</th>\n",
       "      <th>dbytes</th>\n",
       "      <th>sttl</th>\n",
       "      <th>dttl</th>\n",
       "      <th>sload</th>\n",
       "      <th>dload</th>\n",
       "      <th>sloss</th>\n",
       "      <th>...</th>\n",
       "      <th>is_ftp_login</th>\n",
       "      <th>ct_ftp_cmd</th>\n",
       "      <th>ct_flw_http_mthd</th>\n",
       "      <th>ct_src_ltm</th>\n",
       "      <th>ct_srv_dst</th>\n",
       "      <th>is_sm_ips_ports</th>\n",
       "      <th>proto</th>\n",
       "      <th>service</th>\n",
       "      <th>state</th>\n",
       "      <th>attack_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.200687e-07</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.121569</td>\n",
       "      <td>0.114173</td>\n",
       "      <td>8.357948e-05</td>\n",
       "      <td>0.004829</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>119</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.112267e-06</td>\n",
       "      <td>0.000376</td>\n",
       "      <td>0.000363</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.121569</td>\n",
       "      <td>0.114173</td>\n",
       "      <td>1.464196e-05</td>\n",
       "      <td>0.000392</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.0</td>\n",
       "      <td>119</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.273525e-07</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.121569</td>\n",
       "      <td>0.114173</td>\n",
       "      <td>8.715673e-05</td>\n",
       "      <td>0.004942</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.015152</td>\n",
       "      <td>0.106061</td>\n",
       "      <td>0.0</td>\n",
       "      <td>119</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.375953e-07</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.121569</td>\n",
       "      <td>0.114173</td>\n",
       "      <td>7.293329e-05</td>\n",
       "      <td>0.004214</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.121212</td>\n",
       "      <td>0.0</td>\n",
       "      <td>119</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.330429e-07</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.121569</td>\n",
       "      <td>0.114173</td>\n",
       "      <td>8.342890e-05</td>\n",
       "      <td>0.004730</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.121212</td>\n",
       "      <td>0.0</td>\n",
       "      <td>119</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4215056</th>\n",
       "      <td>6.401341e-04</td>\n",
       "      <td>0.005979</td>\n",
       "      <td>0.031994</td>\n",
       "      <td>0.000213</td>\n",
       "      <td>0.031485</td>\n",
       "      <td>0.996078</td>\n",
       "      <td>0.992126</td>\n",
       "      <td>7.152315e-07</td>\n",
       "      <td>0.004839</td>\n",
       "      <td>0.000376</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.054054</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>113</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4215057</th>\n",
       "      <td>6.349819e-10</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.996078</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.474353e-01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006373</td>\n",
       "      <td>0.0</td>\n",
       "      <td>119</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4215058</th>\n",
       "      <td>1.018040e-04</td>\n",
       "      <td>0.000939</td>\n",
       "      <td>0.000545</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.996078</td>\n",
       "      <td>0.992126</td>\n",
       "      <td>1.923820e-06</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000376</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.054054</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>113</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4215059</th>\n",
       "      <td>4.107566e-04</td>\n",
       "      <td>0.004361</td>\n",
       "      <td>0.021366</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>0.021317</td>\n",
       "      <td>0.996078</td>\n",
       "      <td>0.992126</td>\n",
       "      <td>8.615791e-07</td>\n",
       "      <td>0.005356</td>\n",
       "      <td>0.000376</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001282</td>\n",
       "      <td>0.000719</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>113</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4215060</th>\n",
       "      <td>4.344108e-05</td>\n",
       "      <td>0.000939</td>\n",
       "      <td>0.000545</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.996078</td>\n",
       "      <td>0.992126</td>\n",
       "      <td>4.012195e-06</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000376</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.054054</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>113</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4215061 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  dur     spkts     dpkts    sbytes    dbytes      sttl  \\\n",
       "0        1.200687e-07  0.000188  0.000182  0.000009  0.000011  0.121569   \n",
       "1        4.112267e-06  0.000376  0.000363  0.000037  0.000021  0.121569   \n",
       "2        1.273525e-07  0.000188  0.000182  0.000010  0.000012  0.121569   \n",
       "3        1.375953e-07  0.000188  0.000182  0.000009  0.000011  0.121569   \n",
       "4        1.330429e-07  0.000188  0.000182  0.000010  0.000012  0.121569   \n",
       "...               ...       ...       ...       ...       ...       ...   \n",
       "4215056  6.401341e-04  0.005979  0.031994  0.000213  0.031485  0.996078   \n",
       "4215057  6.349819e-10  0.000188  0.000000  0.000143  0.000000  0.996078   \n",
       "4215058  1.018040e-04  0.000939  0.000545  0.000091  0.000018  0.996078   \n",
       "4215059  4.107566e-04  0.004361  0.021366  0.000165  0.021317  0.996078   \n",
       "4215060  4.344108e-05  0.000939  0.000545  0.000077  0.000018  0.996078   \n",
       "\n",
       "             dttl         sload     dload     sloss  ...  is_ftp_login  \\\n",
       "0        0.114173  8.357948e-05  0.004829  0.000000  ...           0.2   \n",
       "1        0.114173  1.464196e-05  0.000392  0.000000  ...           0.2   \n",
       "2        0.114173  8.715673e-05  0.004942  0.000000  ...           0.2   \n",
       "3        0.114173  7.293329e-05  0.004214  0.000000  ...           0.2   \n",
       "4        0.114173  8.342890e-05  0.004730  0.000000  ...           0.2   \n",
       "...           ...           ...       ...       ...  ...           ...   \n",
       "4215056  0.992126  7.152315e-07  0.004839  0.000376  ...           0.0   \n",
       "4215057  0.000000  2.474353e-01  0.000000  0.000000  ...           0.0   \n",
       "4215058  0.992126  1.923820e-06  0.000017  0.000376  ...           0.0   \n",
       "4215059  0.992126  8.615791e-07  0.005356  0.000376  ...           0.0   \n",
       "4215060  0.992126  4.012195e-06  0.000044  0.000376  ...           0.0   \n",
       "\n",
       "         ct_ftp_cmd  ct_flw_http_mthd  ct_src_ltm  ct_srv_dst  \\\n",
       "0          0.111111          0.027027    0.030303    0.090909   \n",
       "1          0.111111          0.027027    0.030303    0.045455   \n",
       "2          0.111111          0.027027    0.015152    0.106061   \n",
       "3          0.111111          0.027027    0.000000    0.121212   \n",
       "4          0.111111          0.027027    0.000000    0.121212   \n",
       "...             ...               ...         ...         ...   \n",
       "4215056    0.000000          0.054054    0.000000    0.000000   \n",
       "4215057    0.000000          0.000000    0.000000    0.006373   \n",
       "4215058    0.000000          0.054054    0.000000    0.000000   \n",
       "4215059    0.000000          0.001282    0.000719    0.000000   \n",
       "4215060    0.000000          0.054054    0.000000    0.000000   \n",
       "\n",
       "         is_sm_ips_ports  proto  service  state  attack_cat  \n",
       "0                    0.0    119        2      2           6  \n",
       "1                    0.0    119        0      2           6  \n",
       "2                    0.0    119        2      2           6  \n",
       "3                    0.0    119        2      2           6  \n",
       "4                    0.0    119        2      2           6  \n",
       "...                  ...    ...      ...    ...         ...  \n",
       "4215056              0.0    113        5      5           9  \n",
       "4215057              0.0    119        0      6           9  \n",
       "4215058              0.0    113        5      5           9  \n",
       "4215059              0.0    113        5      5           9  \n",
       "4215060              0.0    113        5      5           9  \n",
       "\n",
       "[4215061 rows x 42 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d1c67509-458f-4b7d-9613-5dd46d75c681",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"attack_cat\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "919b4a47-ad41-4097-8853-4e121c201d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\"attack_cat\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "92744ca8-bbaa-4c73-94c5-aff70fb7aa2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8b809630-12c3-43d2-8f2f-2a41ba7ac3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a9c8e3ff-4a0a-45da-bf8c-7746bed3e177",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "149f5b22-0cd0-4a74-9926-b72217607c10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "87217dd5-459f-4219-b710-6d5de4c213e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "del X\n",
    "del df\n",
    "del y\n",
    "del labelencoder\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "10b8c60a-bfe6-4839-8c52-24ab8322ac00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "dc58ece2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m92205/92205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m736s\u001b[0m 8ms/step - accuracy: 0.7565 - loss: 0.6502 - val_accuracy: 0.8353 - val_loss: 0.4315\n",
      "Epoch 2/10\n",
      "\u001b[1m92205/92205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m712s\u001b[0m 8ms/step - accuracy: 0.8267 - loss: 0.4520 - val_accuracy: 0.8290 - val_loss: 0.4506\n",
      "Epoch 3/10\n",
      "\u001b[1m92205/92205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m710s\u001b[0m 8ms/step - accuracy: 0.8311 - loss: 0.4408 - val_accuracy: 0.8348 - val_loss: 0.4282\n",
      "Epoch 4/10\n",
      "\u001b[1m92205/92205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m790s\u001b[0m 9ms/step - accuracy: 0.8472 - loss: 125.4282 - val_accuracy: 0.8551 - val_loss: 0.3766\n",
      "Epoch 5/10\n",
      "\u001b[1m92205/92205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m739s\u001b[0m 8ms/step - accuracy: 0.8529 - loss: 0.3813 - val_accuracy: 0.8530 - val_loss: 0.3776\n",
      "Epoch 6/10\n",
      "\u001b[1m92205/92205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m710s\u001b[0m 8ms/step - accuracy: 0.8571 - loss: 0.3694 - val_accuracy: 0.8553 - val_loss: 0.3679\n",
      "Epoch 7/10\n",
      "\u001b[1m92205/92205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m731s\u001b[0m 8ms/step - accuracy: 0.8589 - loss: 0.3692 - val_accuracy: 0.8608 - val_loss: 0.3577\n",
      "Epoch 8/10\n",
      "\u001b[1m92205/92205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m706s\u001b[0m 8ms/step - accuracy: 0.8604 - loss: 0.3586 - val_accuracy: 0.8528 - val_loss: 0.3744\n",
      "Epoch 9/10\n",
      "\u001b[1m92205/92205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m701s\u001b[0m 8ms/step - accuracy: 0.8591 - loss: 4.9317 - val_accuracy: 0.6894 - val_loss: 1.6495\n",
      "Epoch 10/10\n",
      "\u001b[1m92205/92205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m728s\u001b[0m 8ms/step - accuracy: 0.7858 - loss: 0.6418 - val_accuracy: 0.8561 - val_loss: 0.3742\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2907b925870>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "X_train = np.array(X_train).reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_test = np.array(X_test).reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "# Define the model (same as before)\n",
    "model = keras.Sequential([\n",
    "  keras.Input(shape=(41,1)),\n",
    "  keras.layers.LSTM(50, activation=\"relu\",return_sequences=False),\n",
    "  keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "# Compile the model with optimizer, loss function, and metrics\n",
    "model.compile(optimizer=\"adam\",loss=\"sparse_categorical_crossentropy\",metrics=[\"accuracy\"])\n",
    "# Train the model (replace with your training data)\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8f0a2b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtraTreeClassifier:\n",
      "Accuracy: 0.9025305274179352\n",
      "Precision: 0.9079633158407548\n",
      "Recall: 0.9025305274179352\n",
      "F1 Score: 0.9021033481794825\n",
      "\n",
      "DecisionTreeClassifier:\n",
      "Accuracy: 0.9070792926005857\n",
      "Precision: 0.9125670998411434\n",
      "Recall: 0.9070792926005857\n",
      "F1 Score: 0.9067456395532058\n",
      "\n",
      "RandomForestClassifier:\n",
      "Accuracy: 0.9137964712273995\n",
      "Precision: 0.9203992925254386\n",
      "Recall: 0.9137964712273995\n",
      "F1 Score: 0.9139836819960522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dodooz\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LogisticRegression:\n",
      "Accuracy: 0.7727713067182067\n",
      "Precision: 0.7766977042089434\n",
      "Recall: 0.7727713067182067\n",
      "F1 Score: 0.766817962343783\n",
      "\n",
      "LinearDiscriminantAnalysis:\n",
      "Accuracy: 0.7534556617970943\n",
      "Precision: 0.7830578853841017\n",
      "Recall: 0.7534556617970943\n",
      "F1 Score: 0.7484279963917003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dodooz\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "QuadraticDiscriminantAnalysis:\n",
      "Accuracy: 0.7221583859159095\n",
      "Precision: 0.7471794085215752\n",
      "Recall: 0.7221583859159095\n",
      "F1 Score: 0.715056416890514\n",
      "\n",
      "RidgeClassifier:\n",
      "Accuracy: 0.7418441320375574\n",
      "Precision: 0.7467945288932265\n",
      "Recall: 0.7418441320375574\n",
      "F1 Score: 0.7137356000858764\n",
      "\n",
      "AdaBoostClassifier:\n",
      "Accuracy: 0.473518389205698\n",
      "Precision: 0.6863561089363764\n",
      "Recall: 0.473518389205698\n",
      "F1 Score: 0.5082261734146074\n",
      "\n",
      "GradientBoostingClassifier:\n",
      "Accuracy: 0.8782351233947453\n",
      "Precision: 0.8876749733414683\n",
      "Recall: 0.8782351233947453\n",
      "F1 Score: 0.878546261311675\n",
      "\n",
      "BaggingClassifier:\n",
      "Accuracy: 0.912311321538071\n",
      "Precision: 0.9190408133619888\n",
      "Recall: 0.912311321538071\n",
      "F1 Score: 0.9125991850152443\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import ExtraTreeClassifier, DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, BaggingClassifier\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Assuming X_train, X_test, y_train, y_test are already defined\n",
    "\n",
    "def evaluate_model(model, X_train, y_train, X_test, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "# ExtraTreeClassifier\n",
    "extra_tree_model = ExtraTreeClassifier()\n",
    "accuracy, precision, recall, f1 = evaluate_model(extra_tree_model, X_train, y_train, X_test, y_test)\n",
    "print(\"ExtraTreeClassifier:\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "\n",
    "# DecisionTreeClassifier\n",
    "decision_tree_model = DecisionTreeClassifier()\n",
    "accuracy, precision, recall, f1 = evaluate_model(decision_tree_model, X_train, y_train, X_test, y_test)\n",
    "print(\"\\nDecisionTreeClassifier:\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "\n",
    "# RandomForestClassifier\n",
    "random_forest_model = RandomForestClassifier()\n",
    "accuracy, precision, recall, f1 = evaluate_model(random_forest_model, X_train, y_train, X_test, y_test)\n",
    "print(\"\\nRandomForestClassifier:\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "\n",
    "# LogisticRegression\n",
    "logistic_regression_model = LogisticRegression(max_iter=1000)\n",
    "accuracy, precision, recall, f1 = evaluate_model(logistic_regression_model, X_train, y_train, X_test, y_test)\n",
    "print(\"\\nLogisticRegression:\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "\n",
    "# LinearDiscriminantAnalysis\n",
    "lda_model = LinearDiscriminantAnalysis()\n",
    "accuracy, precision, recall, f1 = evaluate_model(lda_model, X_train, y_train, X_test, y_test)\n",
    "print(\"\\nLinearDiscriminantAnalysis:\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "\n",
    "# QuadraticDiscriminantAnalysis\n",
    "qda_model = QuadraticDiscriminantAnalysis()\n",
    "accuracy, precision, recall, f1 = evaluate_model(qda_model, X_train, y_train, X_test, y_test)\n",
    "print(\"\\nQuadraticDiscriminantAnalysis:\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "\n",
    "# RidgeClassifier\n",
    "ridge_model = RidgeClassifier()\n",
    "accuracy, precision, recall, f1 = evaluate_model(ridge_model, X_train, y_train, X_test, y_test)\n",
    "print(\"\\nRidgeClassifier:\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "\n",
    "# AdaBoostClassifier\n",
    "adaboost_model = AdaBoostClassifier()\n",
    "accuracy, precision, recall, f1 = evaluate_model(adaboost_model, X_train, y_train, X_test, y_test)\n",
    "print(\"\\nAdaBoostClassifier:\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "\n",
    "# GradientBoostingClassifier\n",
    "gradient_boosting_model = GradientBoostingClassifier()\n",
    "accuracy, precision, recall, f1 = evaluate_model(gradient_boosting_model, X_train, y_train, X_test, y_test)\n",
    "print(\"\\nGradientBoostingClassifier:\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "\n",
    "# BaggingClassifier\n",
    "bagging_model = BaggingClassifier()\n",
    "accuracy, precision, recall, f1 = evaluate_model(bagging_model, X_train, y_train, X_test, y_test)\n",
    "print(\"\\nBaggingClassifier:\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "76d67d29-4011-4017-9e17-5c1cd28d5d4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m92205/92205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 896us/step - accuracy: 0.8030 - loss: 0.5109 - val_accuracy: 0.8387 - val_loss: 0.4014\n",
      "Epoch 2/10\n",
      "\u001b[1m92205/92205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 924us/step - accuracy: 0.8409 - loss: 0.3966 - val_accuracy: 0.8491 - val_loss: 0.3779\n",
      "Epoch 3/10\n",
      "\u001b[1m92205/92205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 972us/step - accuracy: 0.8483 - loss: 0.3767 - val_accuracy: 0.8470 - val_loss: 0.3784\n",
      "Epoch 4/10\n",
      "\u001b[1m92205/92205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 974us/step - accuracy: 0.8506 - loss: 0.3692 - val_accuracy: 0.8523 - val_loss: 0.3626\n",
      "Epoch 5/10\n",
      "\u001b[1m92205/92205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 965us/step - accuracy: 0.8520 - loss: 0.3646 - val_accuracy: 0.8543 - val_loss: 0.3607\n",
      "Epoch 6/10\n",
      "\u001b[1m92205/92205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 963us/step - accuracy: 0.8534 - loss: 0.3601 - val_accuracy: 0.8564 - val_loss: 0.3528\n",
      "Epoch 7/10\n",
      "\u001b[1m92205/92205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 970us/step - accuracy: 0.8530 - loss: 0.3598 - val_accuracy: 0.8515 - val_loss: 0.3602\n",
      "Epoch 8/10\n",
      "\u001b[1m92205/92205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 995us/step - accuracy: 0.8542 - loss: 0.3562 - val_accuracy: 0.8567 - val_loss: 0.3531\n",
      "Epoch 9/10\n",
      "\u001b[1m92205/92205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 914us/step - accuracy: 0.8545 - loss: 0.3554 - val_accuracy: 0.8548 - val_loss: 0.3563\n",
      "Epoch 10/10\n",
      "\u001b[1m92205/92205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 885us/step - accuracy: 0.8557 - loss: 0.3530 - val_accuracy: 0.8557 - val_loss: 0.3480\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1d2ee23f970>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RF-SFS-ANN\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Assuming your data is already preprocessed and loaded into X_train and y_train\n",
    "\n",
    "# Data reshaping is likely correct: no need to reshape if labels are integers\n",
    "# X_train = np.array(X_train).reshape(X_train.shape[0], X_train.shape[1])  # Uncomment if needed (Scenario 1)\n",
    "# X_test = np.array(X_test).reshape(X_test.shape[0], X_test.shape[1])\n",
    "\n",
    "# Define the model (assuming integer labels)\n",
    "model = keras.Sequential([\n",
    "  keras.Input(shape=(X_train.shape[1],)),  # Adjust input shape based on your data\n",
    "  keras.layers.Dense(50, activation=\"tanh\"),\n",
    "  keras.layers.Dense(50, activation=\"tanh\"),\n",
    "  keras.layers.Dense(50, activation=\"tanh\"),\n",
    "  keras.layers.Dense(10, activation=\"softmax\"),  # 10 neurons for 10 classes\n",
    "])\n",
    "\n",
    "# Compile the model with optimizer and loss function (assuming classification task)\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "7c8bf826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m29506/29506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1ms/step - accuracy: 0.8014 - loss: 0.5158 - val_accuracy: 0.8467 - val_loss: 0.3834\n",
      "Epoch 2/100\n",
      "\u001b[1m29506/29506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 1ms/step - accuracy: 0.8477 - loss: 0.3785 - val_accuracy: 0.8549 - val_loss: 0.3557\n",
      "Epoch 3/100\n",
      "\u001b[1m29506/29506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 1ms/step - accuracy: 0.8535 - loss: 0.3608 - val_accuracy: 0.8579 - val_loss: 0.3481\n",
      "Epoch 4/100\n",
      "\u001b[1m29506/29506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 1ms/step - accuracy: 0.8563 - loss: 0.3522 - val_accuracy: 0.8552 - val_loss: 0.3507\n",
      "Epoch 5/100\n",
      "\u001b[1m29506/29506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 1ms/step - accuracy: 0.8585 - loss: 0.3458 - val_accuracy: 0.8595 - val_loss: 0.3425\n",
      "Epoch 6/100\n",
      "\u001b[1m29506/29506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 1ms/step - accuracy: 0.8601 - loss: 0.3411 - val_accuracy: 0.8534 - val_loss: 0.3648\n",
      "Epoch 7/100\n",
      "\u001b[1m29506/29506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 1ms/step - accuracy: 0.8619 - loss: 0.3370 - val_accuracy: 0.8606 - val_loss: 0.3356\n",
      "Epoch 8/100\n",
      "\u001b[1m29506/29506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 1ms/step - accuracy: 0.8632 - loss: 0.3332 - val_accuracy: 0.8629 - val_loss: 0.3328\n",
      "Epoch 9/100\n",
      "\u001b[1m29506/29506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 1ms/step - accuracy: 0.8648 - loss: 0.3299 - val_accuracy: 0.8658 - val_loss: 0.3275\n",
      "Epoch 10/100\n",
      "\u001b[1m29506/29506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 1ms/step - accuracy: 0.8659 - loss: 0.3269 - val_accuracy: 0.8652 - val_loss: 0.3301\n",
      "Epoch 11/100\n",
      "\u001b[1m29506/29506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 1ms/step - accuracy: 0.8666 - loss: 0.3253 - val_accuracy: 0.8673 - val_loss: 0.3244\n",
      "Epoch 12/100\n",
      "\u001b[1m29506/29506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 1ms/step - accuracy: 0.8677 - loss: 0.3232 - val_accuracy: 0.8690 - val_loss: 0.3223\n",
      "Epoch 13/100\n",
      "\u001b[1m29506/29506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 1ms/step - accuracy: 0.8688 - loss: 0.3208 - val_accuracy: 0.8678 - val_loss: 0.3238\n",
      "Epoch 14/100\n",
      "\u001b[1m29506/29506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 1ms/step - accuracy: 0.8696 - loss: 0.3187 - val_accuracy: 0.8673 - val_loss: 0.3222\n",
      "Epoch 15/100\n",
      "\u001b[1m29506/29506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 1ms/step - accuracy: 0.8702 - loss: 0.3176 - val_accuracy: 0.8687 - val_loss: 0.3230\n",
      "Epoch 16/100\n",
      "\u001b[1m29506/29506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 1ms/step - accuracy: 0.8708 - loss: 0.3169 - val_accuracy: 0.8715 - val_loss: 0.3137\n",
      "Epoch 17/100\n",
      "\u001b[1m29506/29506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 1ms/step - accuracy: 0.8716 - loss: 0.3143 - val_accuracy: 0.8721 - val_loss: 0.3141\n",
      "Epoch 18/100\n",
      "\u001b[1m29506/29506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 1ms/step - accuracy: 0.8720 - loss: 0.3130 - val_accuracy: 0.8718 - val_loss: 0.3159\n",
      "Epoch 19/100\n",
      "\u001b[1m29506/29506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 1ms/step - accuracy: 0.8729 - loss: 0.3114 - val_accuracy: 0.8723 - val_loss: 0.3129\n",
      "Epoch 20/100\n",
      "\u001b[1m29506/29506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 1ms/step - accuracy: 0.8730 - loss: 0.3110 - val_accuracy: 0.8740 - val_loss: 0.3097\n",
      "Epoch 21/100\n",
      "\u001b[1m29506/29506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 1ms/step - accuracy: 0.8735 - loss: 0.3094 - val_accuracy: 0.8736 - val_loss: 0.3111\n",
      "Epoch 22/100\n",
      "\u001b[1m29506/29506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 1ms/step - accuracy: 0.8736 - loss: 0.3090 - val_accuracy: 0.8727 - val_loss: 0.3122\n",
      "Epoch 23/100\n",
      "\u001b[1m29506/29506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 1ms/step - accuracy: 0.8745 - loss: 0.3071 - val_accuracy: 0.8744 - val_loss: 0.3086\n",
      "Epoch 24/100\n",
      "\u001b[1m29506/29506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 1ms/step - accuracy: 0.8747 - loss: 0.3065 - val_accuracy: 0.8745 - val_loss: 0.3060\n",
      "Epoch 25/100\n",
      "\u001b[1m29506/29506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 1ms/step - accuracy: 0.8752 - loss: 0.3056 - val_accuracy: 0.8731 - val_loss: 0.3109\n",
      "Epoch 26/100\n",
      "\u001b[1m29506/29506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 1ms/step - accuracy: 0.8752 - loss: 0.3051 - val_accuracy: 0.8740 - val_loss: 0.3071\n",
      "Epoch 27/100\n",
      "\u001b[1m29506/29506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 1ms/step - accuracy: 0.8757 - loss: 0.3038 - val_accuracy: 0.8758 - val_loss: 0.3027\n",
      "Epoch 28/100\n",
      "\u001b[1m29506/29506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 1ms/step - accuracy: 0.8760 - loss: 0.3033 - val_accuracy: 0.8742 - val_loss: 0.3081\n",
      "Epoch 29/100\n",
      "\u001b[1m29506/29506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 1ms/step - accuracy: 0.8763 - loss: 0.3026 - val_accuracy: 0.8745 - val_loss: 0.3066\n",
      "Epoch 30/100\n",
      "\u001b[1m29506/29506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 1ms/step - accuracy: 0.8764 - loss: 0.3025 - val_accuracy: 0.8760 - val_loss: 0.3051\n",
      "Epoch 31/100\n",
      "\u001b[1m29506/29506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 1ms/step - accuracy: 0.8766 - loss: 0.3021 - val_accuracy: 0.8751 - val_loss: 0.3082\n",
      "Epoch 32/100\n",
      "\u001b[1m29506/29506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 1ms/step - accuracy: 0.8768 - loss: 0.3010 - val_accuracy: 0.8761 - val_loss: 0.3049\n",
      "Epoch 33/100\n",
      "\u001b[1m29506/29506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 1ms/step - accuracy: 0.8776 - loss: 0.2998 - val_accuracy: 0.8752 - val_loss: 0.3083\n",
      "Epoch 34/100\n",
      "\u001b[1m29506/29506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 1ms/step - accuracy: 0.8776 - loss: 0.2996 - val_accuracy: 0.8761 - val_loss: 0.3049\n",
      "Epoch 35/100\n",
      "\u001b[1m29506/29506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 1ms/step - accuracy: 0.8778 - loss: 0.2992 - val_accuracy: 0.8636 - val_loss: 0.3330\n",
      "Epoch 36/100\n",
      "\u001b[1m29506/29506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 1ms/step - accuracy: 0.8777 - loss: 0.2989 - val_accuracy: 0.8777 - val_loss: 0.3014\n",
      "Epoch 37/100\n",
      "\u001b[1m29506/29506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 1ms/step - accuracy: 0.8782 - loss: 0.2984 - val_accuracy: 0.8782 - val_loss: 0.2989\n",
      "Epoch 38/100\n",
      "\u001b[1m29506/29506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 1ms/step - accuracy: 0.8783 - loss: 0.2975 - val_accuracy: 0.8782 - val_loss: 0.2992\n",
      "Epoch 39/100\n",
      "\u001b[1m29506/29506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 1ms/step - accuracy: 0.8784 - loss: 0.2976 - val_accuracy: 0.8784 - val_loss: 0.2991\n",
      "Epoch 40/100\n",
      "\u001b[1m29506/29506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 1ms/step - accuracy: 0.8791 - loss: 0.2961 - val_accuracy: 0.8779 - val_loss: 0.2998\n",
      "Epoch 41/100\n",
      "\u001b[1m29506/29506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 1ms/step - accuracy: 0.8787 - loss: 0.2966 - val_accuracy: 0.8769 - val_loss: 0.3027\n",
      "Epoch 42/100\n",
      "\u001b[1m29506/29506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 1ms/step - accuracy: 0.8792 - loss: 0.2956 - val_accuracy: 0.8779 - val_loss: 0.2982\n",
      "Epoch 43/100\n",
      "\u001b[1m29506/29506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 1ms/step - accuracy: 0.8791 - loss: 0.2951 - val_accuracy: 0.8771 - val_loss: 0.2983\n",
      "Epoch 44/100\n",
      "\u001b[1m29506/29506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 1ms/step - accuracy: 0.8791 - loss: 0.2955 - val_accuracy: 0.8779 - val_loss: 0.3016\n",
      "Epoch 45/100\n",
      "\u001b[1m29506/29506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 1ms/step - accuracy: 0.8799 - loss: 0.2942 - val_accuracy: 0.8757 - val_loss: 0.3072\n",
      "Epoch 46/100\n",
      "\u001b[1m29506/29506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 1ms/step - accuracy: 0.8796 - loss: 0.2949 - val_accuracy: 0.8773 - val_loss: 0.3010\n",
      "Epoch 47/100\n",
      "\u001b[1m29506/29506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 1ms/step - accuracy: 0.8797 - loss: 0.2948 - val_accuracy: 0.8789 - val_loss: 0.2987\n",
      "Epoch 48/100\n",
      "\u001b[1m29506/29506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 1ms/step - accuracy: 0.8799 - loss: 0.2939 - val_accuracy: 0.8782 - val_loss: 0.2997\n",
      "Epoch 49/100\n",
      "\u001b[1m29506/29506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 1ms/step - accuracy: 0.8798 - loss: 0.2935 - val_accuracy: 0.8794 - val_loss: 0.2979\n",
      "Epoch 50/100\n",
      "\u001b[1m29506/29506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 1ms/step - accuracy: 0.8802 - loss: 0.2928 - val_accuracy: 0.8795 - val_loss: 0.2957\n",
      "Epoch 51/100\n",
      "\u001b[1m29506/29506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 1ms/step - accuracy: 0.8802 - loss: 0.2927 - val_accuracy: 0.8790 - val_loss: 0.2964\n",
      "Epoch 52/100\n",
      "\u001b[1m29506/29506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 1ms/step - accuracy: 0.8805 - loss: 0.2925 - val_accuracy: 0.8803 - val_loss: 0.2956\n",
      "Epoch 53/100\n",
      "\u001b[1m29506/29506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 1ms/step - accuracy: 0.8808 - loss: 0.2918 - val_accuracy: 0.8795 - val_loss: 0.2937\n",
      "Epoch 54/100\n",
      "\u001b[1m29506/29506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 1ms/step - accuracy: 0.8810 - loss: 0.2915 - val_accuracy: 0.8808 - val_loss: 0.2936\n",
      "Epoch 55/100\n",
      "\u001b[1m29506/29506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 1ms/step - accuracy: 0.8810 - loss: 0.2911 - val_accuracy: 0.8799 - val_loss: 0.2958\n",
      "Epoch 56/100\n",
      "\u001b[1m29506/29506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 1ms/step - accuracy: 0.8809 - loss: 0.2911 - val_accuracy: 0.8784 - val_loss: 0.2966\n",
      "Epoch 57/100\n",
      "\u001b[1m29506/29506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 1ms/step - accuracy: 0.8816 - loss: 0.2900 - val_accuracy: 0.8797 - val_loss: 0.2958\n",
      "Epoch 58/100\n",
      "\u001b[1m29506/29506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 1ms/step - accuracy: 0.8811 - loss: 0.2906 - val_accuracy: 0.8798 - val_loss: 0.2957\n",
      "Epoch 59/100\n",
      "\u001b[1m29506/29506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 1ms/step - accuracy: 0.8816 - loss: 0.2896 - val_accuracy: 0.8793 - val_loss: 0.2985\n",
      "Epoch 60/100\n",
      "\u001b[1m29506/29506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 1ms/step - accuracy: 0.8817 - loss: 0.2894 - val_accuracy: 0.8807 - val_loss: 0.2925\n",
      "Epoch 61/100\n",
      "\u001b[1m29506/29506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 1ms/step - accuracy: 0.8816 - loss: 0.2893 - val_accuracy: 0.8803 - val_loss: 0.2948\n",
      "Epoch 62/100\n",
      "\u001b[1m29506/29506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 1ms/step - accuracy: 0.8821 - loss: 0.2887 - val_accuracy: 0.8803 - val_loss: 0.2944\n",
      "Epoch 63/100\n",
      "\u001b[1m29506/29506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 1ms/step - accuracy: 0.8819 - loss: 0.2891 - val_accuracy: 0.8788 - val_loss: 0.2973\n",
      "Epoch 64/100\n",
      "\u001b[1m29506/29506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 1ms/step - accuracy: 0.8819 - loss: 0.2889 - val_accuracy: 0.8796 - val_loss: 0.2953\n",
      "Epoch 65/100\n",
      "\u001b[1m29506/29506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 1ms/step - accuracy: 0.8818 - loss: 0.2885 - val_accuracy: 0.8815 - val_loss: 0.2919\n",
      "Epoch 66/100\n",
      "\u001b[1m29506/29506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 1ms/step - accuracy: 0.8818 - loss: 0.2884 - val_accuracy: 0.8804 - val_loss: 0.2951\n",
      "Epoch 67/100\n",
      "\u001b[1m29506/29506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 1ms/step - accuracy: 0.8823 - loss: 0.2877 - val_accuracy: 0.8796 - val_loss: 0.2917\n",
      "Epoch 68/100\n",
      "\u001b[1m29506/29506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 1ms/step - accuracy: 0.8824 - loss: 0.2877 - val_accuracy: 0.8793 - val_loss: 0.2970\n",
      "Epoch 69/100\n",
      "\u001b[1m29506/29506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 1ms/step - accuracy: 0.8824 - loss: 0.2877 - val_accuracy: 0.8811 - val_loss: 0.2927\n",
      "Epoch 70/100\n",
      "\u001b[1m29506/29506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 1ms/step - accuracy: 0.8823 - loss: 0.2877 - val_accuracy: 0.8823 - val_loss: 0.2912\n",
      "Epoch 71/100\n",
      "\u001b[1m29506/29506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 1ms/step - accuracy: 0.8824 - loss: 0.2872 - val_accuracy: 0.8809 - val_loss: 0.2923\n",
      "Epoch 72/100\n",
      "\u001b[1m29506/29506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 1ms/step - accuracy: 0.8828 - loss: 0.2869 - val_accuracy: 0.8808 - val_loss: 0.2909\n",
      "Epoch 73/100\n",
      "\u001b[1m29506/29506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 1ms/step - accuracy: 0.8825 - loss: 0.2869 - val_accuracy: 0.8823 - val_loss: 0.2895\n",
      "Epoch 74/100\n",
      "\u001b[1m29506/29506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 1ms/step - accuracy: 0.8832 - loss: 0.2860 - val_accuracy: 0.8801 - val_loss: 0.2958\n",
      "Epoch 75/100\n",
      "\u001b[1m29506/29506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 1ms/step - accuracy: 0.8827 - loss: 0.2870 - val_accuracy: 0.8816 - val_loss: 0.2898\n",
      "Epoch 76/100\n",
      "\u001b[1m29506/29506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 1ms/step - accuracy: 0.8831 - loss: 0.2855 - val_accuracy: 0.8823 - val_loss: 0.2902\n",
      "Epoch 77/100\n",
      "\u001b[1m29506/29506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 1ms/step - accuracy: 0.8827 - loss: 0.2872 - val_accuracy: 0.8820 - val_loss: 0.2911\n",
      "Epoch 78/100\n",
      "\u001b[1m29506/29506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 1ms/step - accuracy: 0.8833 - loss: 0.2860 - val_accuracy: 0.8822 - val_loss: 0.2876\n",
      "Epoch 79/100\n",
      "\u001b[1m29506/29506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 1ms/step - accuracy: 0.8831 - loss: 0.2861 - val_accuracy: 0.8774 - val_loss: 0.2986\n",
      "Epoch 80/100\n",
      "\u001b[1m29506/29506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 1ms/step - accuracy: 0.8830 - loss: 0.2857 - val_accuracy: 0.8818 - val_loss: 0.2898\n",
      "Epoch 81/100\n",
      "\u001b[1m29506/29506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 1ms/step - accuracy: 0.8830 - loss: 0.2856 - val_accuracy: 0.8819 - val_loss: 0.2907\n",
      "Epoch 82/100\n",
      "\u001b[1m29506/29506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1ms/step - accuracy: 0.8832 - loss: 0.2855 - val_accuracy: 0.8809 - val_loss: 0.2901\n",
      "Epoch 83/100\n",
      "\u001b[1m29506/29506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 1ms/step - accuracy: 0.8834 - loss: 0.2847 - val_accuracy: 0.8825 - val_loss: 0.2903\n",
      "Epoch 84/100\n",
      "\u001b[1m29506/29506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 1ms/step - accuracy: 0.8832 - loss: 0.2852 - val_accuracy: 0.8810 - val_loss: 0.2953\n",
      "Epoch 85/100\n",
      "\u001b[1m29506/29506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 1ms/step - accuracy: 0.8834 - loss: 0.2849 - val_accuracy: 0.8816 - val_loss: 0.2920\n",
      "Epoch 86/100\n",
      "\u001b[1m29506/29506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 1ms/step - accuracy: 0.8837 - loss: 0.2846 - val_accuracy: 0.8837 - val_loss: 0.2867\n",
      "Epoch 87/100\n",
      "\u001b[1m29506/29506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 1ms/step - accuracy: 0.8834 - loss: 0.2847 - val_accuracy: 0.8821 - val_loss: 0.2907\n",
      "Epoch 88/100\n",
      "\u001b[1m29506/29506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 1ms/step - accuracy: 0.8838 - loss: 0.2846 - val_accuracy: 0.8830 - val_loss: 0.2873\n",
      "Epoch 89/100\n",
      "\u001b[1m29506/29506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 1ms/step - accuracy: 0.8836 - loss: 0.2842 - val_accuracy: 0.8819 - val_loss: 0.2914\n",
      "Epoch 90/100\n",
      "\u001b[1m29506/29506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 1ms/step - accuracy: 0.8838 - loss: 0.2838 - val_accuracy: 0.8832 - val_loss: 0.2877\n",
      "Epoch 91/100\n",
      "\u001b[1m29506/29506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 1ms/step - accuracy: 0.8836 - loss: 0.2840 - val_accuracy: 0.8821 - val_loss: 0.2894\n",
      "Epoch 92/100\n",
      "\u001b[1m29506/29506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 1ms/step - accuracy: 0.8838 - loss: 0.2840 - val_accuracy: 0.8835 - val_loss: 0.2873\n",
      "Epoch 93/100\n",
      "\u001b[1m29506/29506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 1ms/step - accuracy: 0.8839 - loss: 0.2837 - val_accuracy: 0.8830 - val_loss: 0.2875\n",
      "Epoch 94/100\n",
      "\u001b[1m29506/29506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 1ms/step - accuracy: 0.8841 - loss: 0.2836 - val_accuracy: 0.8835 - val_loss: 0.2865\n",
      "Epoch 95/100\n",
      "\u001b[1m29506/29506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 1ms/step - accuracy: 0.8840 - loss: 0.2830 - val_accuracy: 0.8819 - val_loss: 0.2887\n",
      "Epoch 96/100\n",
      "\u001b[1m29506/29506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 1ms/step - accuracy: 0.8837 - loss: 0.2839 - val_accuracy: 0.8842 - val_loss: 0.2862\n",
      "Epoch 97/100\n",
      "\u001b[1m29506/29506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1ms/step - accuracy: 0.8844 - loss: 0.2826 - val_accuracy: 0.8823 - val_loss: 0.2889\n",
      "Epoch 98/100\n",
      "\u001b[1m29506/29506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 1ms/step - accuracy: 0.8844 - loss: 0.2821 - val_accuracy: 0.8826 - val_loss: 0.2892\n",
      "Epoch 99/100\n",
      "\u001b[1m29506/29506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 1ms/step - accuracy: 0.8842 - loss: 0.2831 - val_accuracy: 0.8831 - val_loss: 0.2874\n",
      "Epoch 100/100\n",
      "\u001b[1m29506/29506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 1ms/step - accuracy: 0.8845 - loss: 0.2825 - val_accuracy: 0.8826 - val_loss: 0.2887\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1d2ef0fd0f0>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DNN\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Assuming your data is already preprocessed and loaded into X_train and y_train\n",
    "\n",
    "\n",
    "# - If your data represents a single feature with multiple observations (sequences):\n",
    "model = keras.Sequential([\n",
    "  keras.Input(shape=(X_train.shape[1],)),  # Adjust input shape based on your data\n",
    "  keras.layers.Dense(100, activation=\"relu\"),\n",
    "  keras.layers.Dense(100, activation=\"relu\"),\n",
    "  keras.layers.Dense(100, activation=\"relu\"),\n",
    "  keras.layers.Dense(10, activation=\"softmax\"),  # 10 neurons for 10 classes\n",
    "])\n",
    "\n",
    "# Compile the model with optimizer and loss function (assuming classification task)\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=100,batch_size=100, validation_data=(X_test, y_test))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afb9ccf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
